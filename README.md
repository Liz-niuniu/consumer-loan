# Consumer Loan â€“ Data Preprocessing & Feature Engineering

![Python](https://img.shields.io/badge/Python-3.9-blue)
![Pandas](https://img.shields.io/badge/Pandas-1.4-green)
![Matplotlib](https://img.shields.io/badge/Matplotlib-3.5-orange)

This project performs comprehensive data cleaning and feature engineering on a consumer loan dataset (30,000 records, 24 features) to prepare it for building a default prediction model. The processed dataset is ready to be used with classification algorithms such as logistic regression, decision trees, or random forests.

## ğŸ” Project Overview
- **Goal**: Transform raw loan repayment data into a structured, clean, and feature-rich dataset suitable for machine learning.
- **Dataset**: 30,000 loan records with features including credit limit, demographic info, repayment statuses over 6 months, bill amounts, and payment amounts.
- **Key Tasks**:
  - Duplicate removal
  - Categorical encoding (gender, education, marriage, default flag)
  - Repayment status analysis: counted occurrences of each status (e.g., "paid on time", "delayed 1 month") across 6 months
  - Crossâ€‘feature combinations (e.g., total early/onâ€‘time payments, total delayed payments grouped by severity)
  - Outlier detection and removal (e.g., conflicting records with perfect payment history but marked as default)
  - Discretization of continuous variables (credit limit, age) using deciles
  - Sophisticated binning of bill amounts (negative values handled separately, then merged with positive deciles)
  - Payment amount discretization based on percentiles
  - Feature selection via correlation with the target (keeping features with correlation > 0.1)

## ğŸ“ Repository Structure
consumer-loan-default-prediction/
â”œâ”€â”€ data/ä¸ªäººæ¶ˆè´¹è´·æ˜¯å¦è¿çº¦.xlsx  â€“ sample data or instructions to obtain
â”œâ”€â”€ notebooks/ # Jupyter notebook with the full analysis
â”‚ â””â”€â”€ eda_feature_engineering.ipynb
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # This file
â”œâ”€â”€ LICENSE # MIT License
â””â”€â”€ .gitignore # Ignores data, notebooks checkpoints, etc.

text

## ğŸš€ How to Use
1. Clone this repository.
2. Install required packages:
   ```bash
   pip install -r requirements.txt
Open and run the notebook notebooks/eda_feature_engineering.ipynb to reproduce the data processing.

The final cleaned dataset (df_m) is ready for modeling. You can extend the notebook by adding a classifier (e.g., sklearn.ensemble.RandomForestClassifier) to build a full prediction pipeline.

ğŸ“Š Results
After preprocessing, the dataset contains 40 features and 29,228 records (after removing duplicates and outliers). The final feature set (selected by correlation > 0.1) includes:

å»¶è¿Ÿè¿˜æ¬¾_2_5_total_cnt (total delayed payments of 2â€“5 months)

è¿˜æ¬¾å»¶è¿ŸäºŒä¸ªæœˆ_cnt (count of 2â€‘month delays)

ä¿¡ç”¨é¢åº¦ (credit limit, discretized)

æŒ‰æ—¶è¿˜æ¬¾_cnt (count of onâ€‘time payments)

10æœˆæ”¯ä»˜é‡‘é¢ (payment amount in Oct, discretized)

â€¦ and 15 other features.

These features show the strongest linear relationship with the target æ˜¯å¦è¿çº¦ (default flag) and can be used directly in classification models.

ğŸ› ï¸ Technologies Used
Python 3.9

pandas, numpy

matplotlib (for histograms)

scikit-learn (only for correlation; modeling can be added)

ğŸ“Œ Future Work
Train and evaluate classification models (logistic regression, random forest, XGBoost) on the processed dataset.

Perform hyperparameter tuning and crossâ€‘validation.

Deploy the best model as a simple API.

ğŸ“„ License
MIT
